# entertaining-machine-learning
In this repository I am implementing from scratch or dealing with some machine learning ideas that interest me. Would like to explore my own ideas.


to implement
- ResNet
- (SimCLR)[simclr/README.md]
- denoising autoencoder

ideas:
- недетерминированный mlp, предсказывающий плотности а не числа на каждом слое. а input на следуюй слой будем семплить каждый раз. what if layers of the network would give us not logits, but distribution parameters of the logits random space. for example mu, sigma. это как есть такая параметризация у диффузоинок, когда мы предсказываем не шум, не картинку, а параметры распределения шума 
- латент диффузиоки как энкодер. существуют энкодеры для картинок (картинки в латентное пространство переводят). Есть специализированные типа первой половины VAE, есть CLIP, который так то и текст и картинки энкодит, но на одних картинках тоже хорош. Еще мы знаем, что можно детерменированно по картинке и промпту с ее описанием найти N(0, I) шум, из которого диффузионка сделает нашу картинку. Чем не энкодер)). Можно попробовать с этим поиграться
- можно попробовать обучать разные группы параметров модели. сначала одну часть  обучить, чтобы лосс на плато вышел. потом другую. и так по кругу. интересно, что будет. например можно учить первую и вторую часть резнета или там просто в каком-то дроблении.
- можно поддерживать матрицы в каком-то виде, например ортонормированные. либо после шагов спуска переделывать, либо как-то похитрее, чтобы сразу хорошие получались
- можно совместить visual transformer со сверточной. то есть что бы VIT не как обычно кушал сырую картинку, а например уже предобработанную или по всякому в комбинациях и разных путях по сети. тогда можно взять лучшее от обоих архитектур и, может даже сделать маленькую супер мощную сеть
- можно сделать multy-had Unet. то есть много не сложных юнетов параллельно. это наверное не то же самое, что увеличить число каналов, тк градиенты весов с разных юнетов совсем друг на друга не влияют, чего не скажешь об одном. еще можно их стакать несколько слоев или рекурентно, хмхммх
- интересно было бы попробовать налажить поредактировать картинку диффузионкой, но маску сделать не фигурой, а просто пиксель через пиксель - сеткой такой. или что-то такое. как диффузионка обработает запрос, если у нее нет возможности его выполнить и надо поддерживать плавность переходов с оригинальной картинкой
- во что ddim переведет белый шум? что будет если засемплить из такого двойного латента? а если не из двойного на n-раз зашумленного, будут ли связаны картики? а что если зашумлять ddimом не чистый шум, а с какого-то таймстепа разшумления? это как-то на сгенериных картинках отразится? скажем если с 10 шага стахастического разшумления картинки дерева мы ddim переведем 100 разных версий в латент и потом разшумим не обуславливаясь на текст, или обуславливаясь. картинки будут похожи?
- я не знаю, как это пременить, но идея, что мы можем поблуждать вокруг латентного представления картинки например в VAE моделях, которую я увидел в видосике очень прикольная. можно блуждать и смотреть, какие получаются картинки. бродить по латентам, наверняка какие-то приколы такие можно и в диффузионках делать. UnifyEdit в целом чем-то в эту сторону и занимается, но наверняка можно как-то еще и круче)))



желания
- хочется маленькой моделькой решить необъятную, по крайней мере на первый взгляд задачу. 100 проц есть такие задачи и модели. 
